{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning from scratch: homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General instructions\n",
    "\n",
    "Complete the exericses listed below in this Jupyter notebook - leaving all of your code in Python cells in the notebook itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When submitting this homework:\n",
    "\n",
    "**Make sure you have put your name at the top of this file**\n",
    "\n",
    "**This is the only file you must submit** \n",
    "    \n",
    "**Make sure all output is present in your notebook prior to submission**\n",
    "\n",
    "**Do not zip your files when uploading to canvas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "from PIL import Image\n",
    "\n",
    "# this is needed to compensate for matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#a50e3e;\">Exercise 1. </span> ZCA sphereing, K-means clustering, and natural image patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Exercise you will use the K-means algorithm (see [Section 11.5 of the course notes](https://jermwatt.github.io/mlrefined/blog_posts/11_Linear_unsupervised_learning/11_5_K_means_clustering.html)) to cluster a set of natural image patches.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to complete the `extract_patches` module below. This module will extract a total of `number_of_pathes` randomly-positioned patches of size `patch_size` from megapixel images listed in `image_list`. When coding `extract_patches` make sure to exclude flat or nearly flat patches, i.e., those wherein the standard deviation of pixel values falls below $0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hint: you can use the line below to convert an image to a numpy array  \n",
    "# image_as_numpy_array = np.array(Image.open(path_to_image).convert('L'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_patches(image_list, number_of_patches, patch_size):\n",
    "\n",
    "    # YOUR CODE GOES HERE.\n",
    "\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have coded up `extract_patches`, activate the following cell to extract $100000$ image patches, each of size $12 \\times 12$, from the four images given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_1 = 'images/bean.jpg'\n",
    "image_2 = 'images/dog.jpg'\n",
    "image_3 = 'images/flyer.jpg'\n",
    "image_4 = 'images/Trey_Matt.png'\n",
    "\n",
    "image_list = [image_1, image_2, image_3, image_4]\n",
    "number_of_patches = 100000\n",
    "patch_size = 12\n",
    "              \n",
    "patches = extract_patches(image_list, number_of_patches, patch_size)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, `patches` must be a matrix of size $144 \\times 100000$ where each column is a flattened/vectorized $12 \\times 12$ patch. The cell below plots the first $100$ patches in `patches` (Note: each column has to be reshaped back into a square before plotting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_images(X):\n",
    "    '''\n",
    "    Function for plotting input images, stacked in columns of input X.\n",
    "    '''\n",
    "    # plotting mechanism taken from excellent answer from stack overflow: https://stackoverflow.com/questions/20057260/how-to-remove-gaps-between-subplots-in-matplotlib\n",
    "    plt.figure(figsize = (6,6))\n",
    "    gs1 = gridspec.GridSpec(10, 10)\n",
    "    gs1.update(wspace=0.05, hspace=0.05) # set the spacing between axes. \n",
    "    \n",
    "    # shape of square version of image\n",
    "    square_shape = int((X.shape[0])**(0.5))\n",
    "\n",
    "    for i in range(min(100,X.shape[1])):\n",
    "        # plot image in panel\n",
    "        ax = plt.subplot(gs1[i])\n",
    "        im = ax.imshow(np.reshape(X[:,i],(square_shape,square_shape)),cmap = 'gray')\n",
    "\n",
    "        # clean up panel\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# Plot the first 100 patches \n",
    "show_images(patches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure><img src=\"Figures/sample_patches.png\" width=\"50%\" height=\"auto\"></figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform ZCA sphereing to normalize `patches`. To do this, you may use and adjust the PCA sphereing code provided in [Section 11.3 of the course notes](https://jermwatt.github.io/mlrefined/blog_posts/11_Linear_unsupervised_learning/11_3_PCA_sphereing.html). Remember, ZCA sphereing differs from PCA sphereing by one simple step (See Figure below and compare with Figure 1 in [Section 11.3 of the course notes](https://jermwatt.github.io/mlrefined/blog_posts/11_Linear_unsupervised_learning/11_3_PCA_sphereing.html)).    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure><img src=\"Figures/ZCA_diagram.png\"></figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "# patches_ZCA_normalized = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate the cell below to plot the first $100$ patches in `patches_ZCA_normalized` - this is the matrix containing ZCA-normalized patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_images(patches_ZCA_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure><img src=\"Figures/sample_ZCA.png\" width=\"50%\" height=\"auto\"></figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform clustering on ZCA normalized patches we make use of `scikit-learn`'s efficient implementation of the K-means algorithm. Activating the cell below will run K-means for a maximum of $2000$ iterations with learned centroids stored in the matrix `centroids`.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform K-means clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# number of clusters\n",
    "num_clusters = 100 \n",
    "\n",
    "clusterer = KMeans(n_clusters=num_clusters, max_iter = 2000, n_init = 1)\n",
    "\n",
    "# fit the algorithm to our dataset\n",
    "clusterer.fit(patches_ZCA_normalized.T)\n",
    "\n",
    "# extract cluster centroids\n",
    "centroids = clusterer.cluster_centers_.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each centroid iself can be viewed as a patch when reshaped into a $12 \\times 12$ matrix. Python cell below plots all these centroids.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_images(centroids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure><img src=\"Figures/sample_centroids.png\" width=\"50%\" height=\"auto\"></figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A majority of these learned centroids look like edge-detectors, e.g., the centroid highlighted in the Figure below representing a horizontal edge detector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure><img src=\"Figures/edge_detector.png\" width=\"70%\" height=\"auto\"></figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you explain why learned centroids resemble edge detectors of varying width and orientation? Hint: see [Section 14.2.1 of the course notes](https://jermwatt.github.io/mlrefined/blog_posts/14_Convolutional_networks/14_2_Edge_histogram_based_features.html).    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YOUR ANSWER GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run K-means again, this time on the data stored in `patches` and plot the learned centroids.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure><img src=\"Figures/sample_unnormalized.png\" width=\"50%\" height=\"auto\"></figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, without normalization, K-means algorithm is incapable of learning edge detector-like patches from the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#a50e3e;\">Exercise 2. </span> Counting the number of tunable weights in a simple CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you want to perform two-class cassification using convolutional neural networks on a training dataset consisting of $50,000$ face and non-face images, each of size $32 \\times 32$. Your CNN has a single convolutional layer followed by a three (hidden) layer MLP as shown in the Figure below.      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure><img src=\"Figures/pipe_1.png\"></figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Exercise you will find the total number of weights to be learned using this CNN architecture having the following specifications:\n",
    "\n",
    "- Number of convolutional kernels: $10$\n",
    "- Size of each convolutional kernel: $3\\times 3$\n",
    "- Pooling window size: $4\\times 4$\n",
    "- Pooling stride = 2 \n",
    "- Number of units/neurons per layer of MLP: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YOUR ANSWER GOES HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
